{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4142f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.3.0\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for tensorflow==2.3.0\u001b[0m\n",
      "Requirement already satisfied: gym in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (0.18.0)\n",
      "Collecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: h5py in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from keras) (1.6.2)\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-5.4.1-cp39-cp39-manylinux1_x86_64.whl (630 kB)\n",
      "\u001b[K     |████████████████████████████████| 630 kB 392 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from keras) (1.20.2)\n",
      "Requirement already satisfied: six in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from h5py->keras) (1.15.0)\n",
      "Installing collected packages: pyyaml, keras\n",
      "Successfully installed keras-2.4.3 pyyaml-5.4.1\n",
      "Collecting keras-rl2\n",
      "  Downloading keras_rl2-1.0.4-py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 203 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: tensorflow>=2.1.0 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from keras-rl2) (2.4.1)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from tensorflow>=2.1.0->keras-rl2) (1.1.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from tensorflow>=2.1.0->keras-rl2) (0.2.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from tensorflow>=2.1.0->keras-rl2) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from tensorflow>=2.1.0->keras-rl2) (2.4.0)\n",
      "Requirement already satisfied: wheel~=0.35 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from tensorflow>=2.1.0->keras-rl2) (0.36.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from tensorflow>=2.1.0->keras-rl2) (3.15.7)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from tensorflow>=2.1.0->keras-rl2) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from tensorflow>=2.1.0->keras-rl2) (1.12)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from tensorflow>=2.1.0->keras-rl2) (3.7.4.3)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: tensorboard~=2.4 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from tensorflow>=2.1.0->keras-rl2) (2.4.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from tensorflow>=2.1.0->keras-rl2) (0.12.0)\n",
      "Requirement already satisfied: six~=1.15.0 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from tensorflow>=2.1.0->keras-rl2) (1.15.0)\n",
      "Collecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl (14.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.9 MB 93 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0.tar.gz (20.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.8 MB 38 kB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt~=1.12.1 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from tensorflow>=2.1.0->keras-rl2) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from tensorflow>=2.1.0->keras-rl2) (1.1.2)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from tensorflow>=2.1.0->keras-rl2) (1.6.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (0.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (49.6.0.post20210108)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (1.28.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (3.3.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (4.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (4.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./miniconda3/envs/OS-proj/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2) (3.0.1)\n",
      "Building wheels for collected packages: grpcio\n",
      "  Building wheel for grpcio (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for grpcio: filename=grpcio-1.32.0-cp39-cp39-linux_x86_64.whl size=3491868 sha256=8cb118e9590e0466e0cf4440ab50a58683c0eb40527a50742579aa7cbba62585\n",
      "  Stored in directory: /home/jason/.cache/pip/wheels/28/95/38/61aa534c5c1a6f5d4af386f1ac4cafa4828c306660e4c861db\n",
      "Successfully built grpcio\n",
      "Installing collected packages: numpy, grpcio, gast, keras-rl2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.2\n",
      "    Uninstalling numpy-1.20.2:\n",
      "      Successfully uninstalled numpy-1.20.2\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.37.0\n",
      "    Uninstalling grpcio-1.37.0:\n",
      "      Successfully uninstalled grpcio-1.37.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.4.0\n",
      "    Uninstalling gast-0.4.0:\n",
      "      Successfully uninstalled gast-0.4.0\n",
      "Successfully installed gast-0.3.3 grpcio-1.32.0 keras-rl2-1.0.4 numpy-1.19.5\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.3.0\n",
    "!pip install gym\n",
    "!pip install keras\n",
    "!pip install keras-rl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5a43b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3cc95d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowerEnv(Env):\n",
    "    def __init__(self, resources=[90, 90], num_tasks=5):\n",
    "        # Actions we can take, down, stay, up\n",
    "        self.action_space = Discrete(num_tasks)\n",
    "        # Temperature array\n",
    "        self.observation_space = Box(low=0, high=90, shape=(num_tasks, len(resources)))\n",
    "        # Set state\n",
    "        self.state_ = np.zeros((num_tasks, 1), dtype=int)\n",
    "        self.limit_ = 0\n",
    "        for lim in resources:\n",
    "            self.state_ = np.append(self.state_, np.random.randint(lim, size=(num_tasks, 1)), axis=1)\n",
    "            \n",
    "        self.reward_ = 0\n",
    "        for lim in resources:\n",
    "            self.limit_+=lim   #Set the total resource limit as sum of resources\n",
    "       \n",
    "        self.num_tasks_ = num_tasks\n",
    "        self.resources_ = resources\n",
    "        \n",
    "    def getSum(self, x ):\n",
    "        if x[0] == 1:\n",
    "            return sum(x)-1\n",
    "        else:\n",
    "            return 0    \n",
    "    \n",
    "    def step(self, actionIdx):\n",
    "        ### update reward\n",
    "        self.reward_ = 0\n",
    "        reward = 0\n",
    "        done = False\n",
    "        #update the state based on action\n",
    "        #case 1, if same task selected then penalize the agent\n",
    "        if self.state_[actionIdx][0] == 1:\n",
    "            sum_res = np.sum(self.state_[actionIdx], axis=0)\n",
    "            reward = -sum_res/10;\n",
    "            return self.state_,reward,done,{}\n",
    "        else:\n",
    "            self.state_[actionIdx][0] = 1\n",
    "       \n",
    "        #collect all the resources for this batch until now.\n",
    "        totReward = sum(np.apply_along_axis( self.getSum, axis=1, arr=self.state_ ))\n",
    "        # get the sum for selected task\n",
    "        sum_res = np.sum(self.state_[actionIdx], axis=0) \n",
    "        if totReward <= self.limit_:\n",
    "            reward = sum_res\n",
    "        else:\n",
    "            reward = -sum_res/10;\n",
    "            done = True\n",
    "            \n",
    "        return self.state_,reward,done,{}\n",
    "\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        print(self.state_)\n",
    "    \n",
    "    def reset(self):\n",
    "        state = np.zeros((self.num_tasks_, 1), dtype=int)\n",
    "        for lim in self.resources_: \n",
    "            state = np.append(state, np.random.randint(lim, size=(self.num_tasks_,1)), axis=1)\n",
    "        self.state_ = state\n",
    "        self.reward_ = 0\n",
    "        return self.state_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bb04959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ShowerEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6c0c53f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.179023 ,  1.8748015],\n",
       "       [46.28507  ,  5.7366257],\n",
       "       [26.175652 , 86.87449  ],\n",
       "       [43.874172 , 44.092007 ],\n",
       "       [51.280857 ,  5.3875194]], dtype=float32)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f72e9e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 38 14]\n",
      " [ 1 78  5]\n",
      " [ 0 12 59]\n",
      " [ 0  7 38]\n",
      " [ 0 18 79]]\n",
      "[[ 0 38 14]\n",
      " [ 1 78  5]\n",
      " [ 0 12 59]\n",
      " [ 0  7 38]\n",
      " [ 0 18 79]]\n",
      "[[ 0 38 14]\n",
      " [ 1 78  5]\n",
      " [ 0 12 59]\n",
      " [ 0  7 38]\n",
      " [ 0 18 79]]\n",
      "[[ 0 38 14]\n",
      " [ 1 78  5]\n",
      " [ 0 12 59]\n",
      " [ 1  7 38]\n",
      " [ 0 18 79]]\n",
      "[[ 0 38 14]\n",
      " [ 1 78  5]\n",
      " [ 0 12 59]\n",
      " [ 1  7 38]\n",
      " [ 0 18 79]]\n",
      "[[ 0 38 14]\n",
      " [ 1 78  5]\n",
      " [ 0 12 59]\n",
      " [ 1  7 38]\n",
      " [ 0 18 79]]\n",
      "[[ 0 38 14]\n",
      " [ 1 78  5]\n",
      " [ 0 12 59]\n",
      " [ 1  7 38]\n",
      " [ 0 18 79]]\n",
      "[[ 0 38 14]\n",
      " [ 1 78  5]\n",
      " [ 0 12 59]\n",
      " [ 1  7 38]\n",
      " [ 0 18 79]]\n",
      "[[ 0 38 14]\n",
      " [ 1 78  5]\n",
      " [ 0 12 59]\n",
      " [ 1  7 38]\n",
      " [ 1 18 79]]\n",
      "Episode:1 Score:73.59999999999998\n",
      "[[ 0 88 48]\n",
      " [ 0 40 80]\n",
      " [ 1 77 56]\n",
      " [ 0 43 83]\n",
      " [ 0 64 88]]\n",
      "[[ 0 88 48]\n",
      " [ 0 40 80]\n",
      " [ 1 77 56]\n",
      " [ 0 43 83]\n",
      " [ 1 64 88]]\n",
      "Episode:2 Score:118.7\n",
      "[[ 1 37 60]\n",
      " [ 0 44 22]\n",
      " [ 0 42 14]\n",
      " [ 0 56  4]\n",
      " [ 0 33 30]]\n",
      "[[ 1 37 60]\n",
      " [ 1 44 22]\n",
      " [ 0 42 14]\n",
      " [ 0 56  4]\n",
      " [ 0 33 30]]\n",
      "[[ 1 37 60]\n",
      " [ 1 44 22]\n",
      " [ 0 42 14]\n",
      " [ 0 56  4]\n",
      " [ 0 33 30]]\n",
      "[[ 1 37 60]\n",
      " [ 1 44 22]\n",
      " [ 0 42 14]\n",
      " [ 0 56  4]\n",
      " [ 0 33 30]]\n",
      "[[ 1 37 60]\n",
      " [ 1 44 22]\n",
      " [ 0 42 14]\n",
      " [ 0 56  4]\n",
      " [ 0 33 30]]\n",
      "[[ 1 37 60]\n",
      " [ 1 44 22]\n",
      " [ 0 42 14]\n",
      " [ 0 56  4]\n",
      " [ 0 33 30]]\n",
      "[[ 1 37 60]\n",
      " [ 1 44 22]\n",
      " [ 0 42 14]\n",
      " [ 1 56  4]\n",
      " [ 0 33 30]]\n",
      "Episode:3 Score:125.9\n",
      "[[ 0 18 34]\n",
      " [ 0 76 55]\n",
      " [ 1 10 41]\n",
      " [ 0 64 43]\n",
      " [ 0 68 44]]\n",
      "[[ 0 18 34]\n",
      " [ 0 76 55]\n",
      " [ 1 10 41]\n",
      " [ 0 64 43]\n",
      " [ 1 68 44]]\n",
      "[[ 0 18 34]\n",
      " [ 0 76 55]\n",
      " [ 1 10 41]\n",
      " [ 0 64 43]\n",
      " [ 1 68 44]]\n",
      "[[ 0 18 34]\n",
      " [ 0 76 55]\n",
      " [ 1 10 41]\n",
      " [ 1 64 43]\n",
      " [ 1 68 44]]\n",
      "Episode:4 Score:142.89999999999998\n",
      "[[ 0 87 13]\n",
      " [ 1 30 75]\n",
      " [ 0 79 85]\n",
      " [ 0 85 16]\n",
      " [ 0 53  1]]\n",
      "[[ 0 87 13]\n",
      " [ 1 30 75]\n",
      " [ 0 79 85]\n",
      " [ 1 85 16]\n",
      " [ 0 53  1]]\n",
      "Episode:5 Score:95.8\n",
      "[[ 0 19 77]\n",
      " [ 0 28 50]\n",
      " [ 0 17 80]\n",
      " [ 0 68 67]\n",
      " [ 1 76 42]]\n",
      "[[ 1 19 77]\n",
      " [ 0 28 50]\n",
      " [ 0 17 80]\n",
      " [ 0 68 67]\n",
      " [ 1 76 42]]\n",
      "Episode:6 Score:109.3\n",
      "[[ 0 25 32]\n",
      " [ 1 39  3]\n",
      " [ 0 56 89]\n",
      " [ 0 21 72]\n",
      " [ 0 59 88]]\n",
      "[[ 0 25 32]\n",
      " [ 1 39  3]\n",
      " [ 0 56 89]\n",
      " [ 1 21 72]\n",
      " [ 0 59 88]]\n",
      "[[ 0 25 32]\n",
      " [ 1 39  3]\n",
      " [ 0 56 89]\n",
      " [ 1 21 72]\n",
      " [ 1 59 88]]\n",
      "Episode:7 Score:122.2\n",
      "[[ 0 57 31]\n",
      " [ 0  6 11]\n",
      " [ 0 10 53]\n",
      " [ 0 23 44]\n",
      " [ 1  1 30]]\n",
      "[[ 0 57 31]\n",
      " [ 0  6 11]\n",
      " [ 1 10 53]\n",
      " [ 0 23 44]\n",
      " [ 1  1 30]]\n",
      "[[ 0 57 31]\n",
      " [ 0  6 11]\n",
      " [ 1 10 53]\n",
      " [ 0 23 44]\n",
      " [ 1  1 30]]\n",
      "[[ 0 57 31]\n",
      " [ 1  6 11]\n",
      " [ 1 10 53]\n",
      " [ 0 23 44]\n",
      " [ 1  1 30]]\n",
      "[[ 1 57 31]\n",
      " [ 1  6 11]\n",
      " [ 1 10 53]\n",
      " [ 0 23 44]\n",
      " [ 1  1 30]]\n",
      "Episode:8 Score:98.69999999999999\n",
      "[[ 0 55 87]\n",
      " [ 0 25 59]\n",
      " [ 0 52 35]\n",
      " [ 1 39 21]\n",
      " [ 0 48 67]]\n",
      "[[ 1 55 87]\n",
      " [ 0 25 59]\n",
      " [ 0 52 35]\n",
      " [ 1 39 21]\n",
      " [ 0 48 67]]\n",
      "Episode:9 Score:46.7\n",
      "[[ 0 12 31]\n",
      " [ 0 54 81]\n",
      " [ 1 61 60]\n",
      " [ 0 34 77]\n",
      " [ 0 80 40]]\n",
      "[[ 0 12 31]\n",
      " [ 0 54 81]\n",
      " [ 1 61 60]\n",
      " [ 0 34 77]\n",
      " [ 0 80 40]]\n",
      "[[ 1 12 31]\n",
      " [ 0 54 81]\n",
      " [ 1 61 60]\n",
      " [ 0 34 77]\n",
      " [ 0 80 40]]\n",
      "[[ 1 12 31]\n",
      " [ 0 54 81]\n",
      " [ 1 61 60]\n",
      " [ 0 34 77]\n",
      " [ 0 80 40]]\n",
      "[[ 1 12 31]\n",
      " [ 0 54 81]\n",
      " [ 1 61 60]\n",
      " [ 0 34 77]\n",
      " [ 1 80 40]]\n",
      "Episode:10 Score:129.50000000000003\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        #env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        print(n_state)\n",
    "        # print(action, \" \", dqn.forward(n_state))\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6c50da4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6d5ffedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 3)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "states = (1, 5, 3)\n",
    "actions = env.action_space.n\n",
    "\n",
    "print(states)\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a3ce7b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(states, actions):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=states))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(actions, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "250fc9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(states, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c3f8476b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 128)               2048      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 12,549\n",
      "Trainable params: 12,549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4a279644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.agents import DQNAgent\n",
    "from rl.policy import EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ece47422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model, actions):\n",
    "    policy = EpsGreedyQPolicy()\n",
    "    memory = SequentialMemory(limit=50000, window_length=1)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=policy, \n",
    "                  nb_actions=actions, nb_steps_warmup=200, target_model_update=1e-2)\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0d74d601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 50000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "10000/10000 [==============================] - 441s 44ms/step - reward: 0.7408\n",
      "538 episodes - episode_reward: 13.916 [-698.200, 175.700] - loss: 274.547 - mse: 8922.320 - mean_q: 108.530\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 448s 45ms/step - reward: -0.2490\n",
      "199 episodes - episode_reward: 26.467 [-782.000, 169.400] - loss: 102.388 - mse: 6267.210 - mean_q: 42.699\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 461s 46ms/step - reward: -0.7828\n",
      "Interval 4 (30000 steps performed)\n",
      " 1739/10000 [====>.........................] - ETA: 5:53 - reward: -0.7228done, took 1424.798 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f61fab60f40>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn = build_agent(model, actions)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mse'])\n",
    "dqn.fit(env, nb_steps=50000, visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9bf29c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 50000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "  181/10000 [..............................] - ETA: 4:12 - reward: -2.8448done, took 4.649 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6247efd460>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.fit(env, nb_steps=50000, visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce28b256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
